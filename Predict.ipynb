{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T21:49:07.853233Z",
     "start_time": "2018-06-02T21:49:05.734313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "from utils import *\n",
    "from models import *\n",
    "from data import *\n",
    "\n",
    "PATH = os.getcwd()\n",
    "DATA_PATH = \"{}/data\".format(PATH)\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict 1600x1600 crops, stitch them to 3200x3200 together and save them for submitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T21:49:09.819112Z",
     "start_time": "2018-06-02T21:49:09.792401Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_and_predict(img, model):\n",
    "    img = img.unsqueeze(0)\n",
    "#     pdb.set_trace()\n",
    "    pred = model(img)[0,0]\n",
    "    pred[pred>0.5] = 1\n",
    "    pred[pred!=1] = 0\n",
    "    return pred\n",
    "\n",
    "debug = False\n",
    "num_gpu = 1\n",
    "name = \"UNet_BN_crop80_lr0.1_noaugm_logloss0.1_dice_0.9_bs256_sample20k\"\n",
    "create_dir(\"subm\")\n",
    "create_dir(\"{}/{}\".format(DATA_PATH, name))\n",
    "class_list = [\"Buildings\", \"Misc. Manmade structures\", \"Road\", \"Track\", \"Trees\", \"Crops\", \"Waterway\",\n",
    "              \"Standing Water\", \"Vehicle Large\", \"Vehicle Small\"]\n",
    "SB = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "for class_nb in range(0, 10):\n",
    "    count = 0\n",
    "    create_dir(\"{}/{}/{}\".format(DATA_PATH, name, class_list[class_nb]))\n",
    "    hps = HyperParams()\n",
    "    hps.update(\"net=UNet_BN,bn=1,classes={}\".format(str(class_nb)))\n",
    "    \n",
    "    model = UNet_BN(hps)\n",
    "    arg_name = \"UNet_BN_{}_crop80_lr0.1_noaugm_logloss0.1_dice_0.9_bs256_sample20k\".format(class_list[class_nb])\n",
    "    checkpoint = torch.load(\"weights/{}/model_best.pth.tar\".format(arg_name))\n",
    "    print(\"Loading {} with {:.3f} Jaccard\".format(\"weights/{}/model_best.pth.tar\".format(arg_name), checkpoint[\"best_jaccard\"]))\n",
    "    model = torch.nn.DataParallel(model, device_ids=list(range(num_gpu))).cuda()\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    model.eval()\n",
    "    \n",
    "    for idx, row in tqdm(SB.iterrows(), total=SB.shape[0]):\n",
    "        id_ = row[0]\n",
    "        kls = row[1] - 1\n",
    "        if kls!=class_nb:\n",
    "            continue\n",
    "        with torch.no_grad():\n",
    "            count += 1\n",
    "#             if count > 20:\n",
    "#                 break\n",
    "#             start = time.time()\n",
    "            img = M(id_, dims=12)\n",
    "#             print(\"loading takes {:.1f}s\".format(time.time()-start))\n",
    "#             start = time.time()\n",
    "            img = cv2.resize(img, (3200,3200))\n",
    "            if debug:\n",
    "                f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 20))\n",
    "                ax1.imshow(stretch_8bit(img[:,:, :3]))\n",
    "#             print(\"resizing takes {:.1f}s\".format(time.time()-start))\n",
    "#             start = time.time()\n",
    "            h, w = img.shape[:2]\n",
    "            \n",
    "            img = torch.from_numpy(img.transpose((2, 0, 1)).copy())\n",
    "            img = normalize(img)\n",
    "\n",
    "            pred_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            img_ = img[:, :int(0.5*h), :int(0.5*w)]\n",
    "            pred_mask[:int(0.5*h), :int(0.5*w)] = process_and_predict(img_, model)\n",
    "            img_ = img[:, :int(0.5*h), int(0.5*w):]\n",
    "            pred_mask[:int(0.5*h), int(0.5*w):] = process_and_predict(img_, model)\n",
    "            img_ = img[:, int(0.5*h):, :int(0.5*w)]\n",
    "            pred_mask[int(0.5*h):, :int(0.5*w)] = process_and_predict(img_, model)\n",
    "            img_ = img[:, int(0.5*h):, int(0.5*w):]\n",
    "            pred_mask[int(0.5*h):, int(0.5*w):] = process_and_predict(img_, model)\n",
    "            if debug:\n",
    "                ax2.imshow(pred_mask*255, cmap=\"gray\")\n",
    "                plt.show()\n",
    "#             print(\"predicting and stitching takes {:.1f}s\".format(time.time()-start))\n",
    "            save_array(\"{}/{}/{}/{}.bc\".format(DATA_PATH, name, class_list[class_nb], id_),  pred_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dstl]",
   "language": "python",
   "name": "conda-env-dstl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "4px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
