{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T20:51:09.005714Z",
     "start_time": "2018-06-02T20:51:06.935878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"\n",
    "from utils import *\n",
    "from models import *\n",
    "from data import *\n",
    "from train_helper import *\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "PATH = os.getcwd()\n",
    "DATA_PATH = \"{}/data\".format(PATH)\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T20:51:09.350184Z",
     "start_time": "2018-06-02T20:51:09.008368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429 Test images\n",
      "20 Train images\n",
      "5 Validation images\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"{}/sample_submission.csv\".format(DATA_PATH))\n",
    "test_ids = np.unique(test_df[\"ImageId\"])\n",
    "print(\"{} Test images\".format(len(np.unique(test_df[\"ImageId\"]))))\n",
    "\n",
    "all_ids = [j.split(\"/\")[-1].split(\".\")[0] for j in glob.glob(\"{}/three_band/*\".format(DATA_PATH))]\n",
    "len(all_ids)\n",
    "\n",
    "DF = pd.read_csv('data/train_wkt_v4.csv')\n",
    "train_ids = list(np.unique(DF[\"ImageId\"]))\n",
    "len(train_ids)\n",
    "\n",
    "val_ids = [\"6100_2_2\", \"6110_1_2\", \"6140_3_1\", \"6160_2_1\", \"6170_0_4\"]\n",
    "for id_ in val_ids:\n",
    "    train_ids.remove(id_)\n",
    "      \n",
    "print(\"{} Train images\".format(len(train_ids)))\n",
    "print(\"{} Validation images\".format(len(val_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T20:51:25.677743Z",
     "start_time": "2018-06-02T20:51:09.351882Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = load_array(\"imgs_12_band.bc\")\n",
    "masks = load_array(\"masks_12_band.bc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T20:51:25.706369Z",
     "start_time": "2018-06-02T20:51:25.679261Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(arg_name, hps):\n",
    "    model = Model(hps)\n",
    "    model.init_optimizer()\n",
    "\n",
    "    trn_dataset = DatasetDSTL(train_ids, imgs=imgs, masks=masks, classes=hps.classes, oversample=hps.oversample, pick_random_idx=True, samples_per_epoch=hps.samples_per_epoch,\n",
    "                              which_dataset=\"train\", transform=transforms.Compose([RandomNumpyCrop(hps.crop_size), OwnToNormalizedTensor()]))\n",
    "    train_loader = torch.utils.data.DataLoader(trn_dataset, batch_size=hps.batch_size, shuffle=True, num_workers=hps.num_workers, pin_memory=True, sampler=None)\n",
    "\n",
    "    val_dataset = DatasetDSTL(val_ids, imgs=imgs, masks=masks, classes=hps.classes, pick_random_idx=False, samples_per_epoch=5, which_dataset=\"val\", transform=transforms.Compose([\n",
    "        NumpyResize((3200, 3200)), OwnToNormalizedTensor()]))\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=hps.num_workers, pin_memory=True, sampler=None)\n",
    "    \n",
    "    logger = Logger(env=arg_name)\n",
    "    \n",
    "    early_stopping = hps.patience*3\n",
    "    best_jaccard, n_iter, early_stopping_counter, total_time = 0, 0, 0, 0\n",
    "    lrs = []\n",
    "    create_dir(\"{}/weights/{}\".format(PATH, arg_name))\n",
    "    writer = SummaryWriter(comment=\"_{}\".format(arg_name))\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(model.optimizer, factor=0.5, verbose=True, patience=hps.patience, mode=\"max\")\n",
    "    writer.add_scalar(\"train/lr\", model.optimizer.param_groups[0][\"lr\"], n_iter)\n",
    "    for epoch in range(0, hps.n_epochs):\n",
    "        # train for one epoch\n",
    "        n_iter, total_time = model.train_epoch(train_loader, epoch, n_iter, total_time, logger, writer)\n",
    "        validate_time = time.time()\n",
    "\n",
    "    #     evaluate on validation set\n",
    "        current_jaccard = model.validate(val_loader, epoch, logger, writer)\n",
    "        scheduler.step(current_jaccard)\n",
    "        lrs.append(model.optimizer.param_groups[0][\"lr\"])\n",
    "        writer.add_scalar(\"train/lr\", model.optimizer.param_groups[0][\"lr\"], n_iter)\n",
    "\n",
    "        # remember best jaccard and save checkpoint\n",
    "        if current_jaccard > best_jaccard:\n",
    "            best_jaccard = current_jaccard\n",
    "            is_best = True\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            if early_stopping_counter>early_stopping:\n",
    "                print(\"Early Stopping\")\n",
    "                break\n",
    "            early_stopping_counter += 1\n",
    "            is_best = False\n",
    "\n",
    "        save_checkpoint({\n",
    "            \"lrs\": lrs, \n",
    "            'epoch': epoch + 1,\n",
    "            'arch': hps.net,\n",
    "            'state_dict': model.net.state_dict(),\n",
    "            'best_jaccard': best_jaccard,\n",
    "            'optimizer' : model.optimizer.state_dict(),\n",
    "        }, is_best, path=\"weights/{}\".format(arg_name))\n",
    "        total_time += time.time()-validate_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T21:11:15.362217Z",
     "start_time": "2018-06-02T20:51:25.708097Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'augment_flips': 0,\n",
      " 'augment_rotations': 0.0,\n",
      " 'batch_size': 256,\n",
      " 'bn': 1,\n",
      " 'classes': [0],\n",
      " 'crop_size': 80,\n",
      " 'dice_loss_weight': 0.9,\n",
      " 'filters_base': 32,\n",
      " 'log_loss_weight': 0.1,\n",
      " 'lr': 0.01,\n",
      " 'n_channels': 12,\n",
      " 'n_epochs': 1000,\n",
      " 'net': 'UNet_BN',\n",
      " 'num_gpu': 1,\n",
      " 'num_workers': 4,\n",
      " 'opt': 'sgd',\n",
      " 'oversample': 0.0,\n",
      " 'patience': 2,\n",
      " 'print_freq': 100,\n",
      " 'samples_per_epoch': 20000,\n",
      " 'weight_decay': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philip/Personal/Dstl-Satellite-Imagery-Feature-Detection-Improved/train_helper.py:66: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  if uwi[0] != 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0] TotalTime: 0.5 mins,  BatchTime: 0.383,  DataTime: 0.017,  Loss: 0.8159,  Jaccard: 0.3090\n",
      " * Loss 0.790 Jaccard 0.229 (Validation)\n",
      "Epoch: [1] TotalTime: 1.1 mins,  BatchTime: 0.320,  DataTime: 0.014,  Loss: 0.6247,  Jaccard: 0.4977\n",
      " * Loss 0.825 Jaccard 0.206 (Validation)\n",
      "Epoch: [2] TotalTime: 1.7 mins,  BatchTime: 0.321,  DataTime: 0.016,  Loss: 0.6050,  Jaccard: 0.5291\n",
      " * Loss 0.725 Jaccard 0.549 (Validation)\n",
      "Epoch: [3] TotalTime: 2.2 mins,  BatchTime: 0.321,  DataTime: 0.015,  Loss: 0.5880,  Jaccard: 0.5674\n",
      " * Loss 0.741 Jaccard 0.476 (Validation)\n",
      "Epoch: [4] TotalTime: 2.8 mins,  BatchTime: 0.329,  DataTime: 0.022,  Loss: 0.5784,  Jaccard: 0.5910\n",
      " * Loss 0.755 Jaccard 0.440 (Validation)\n",
      "Epoch: [5] TotalTime: 3.4 mins,  BatchTime: 0.329,  DataTime: 0.023,  Loss: 0.5814,  Jaccard: 0.5821\n",
      " * Loss 0.722 Jaccard 0.561 (Validation)\n",
      "Epoch: [6] TotalTime: 3.9 mins,  BatchTime: 0.324,  DataTime: 0.017,  Loss: 0.5695,  Jaccard: 0.6130\n",
      " * Loss 0.728 Jaccard 0.548 (Validation)\n",
      "Epoch: [7] TotalTime: 4.5 mins,  BatchTime: 0.321,  DataTime: 0.015,  Loss: 0.5759,  Jaccard: 0.5961\n",
      " * Loss 0.720 Jaccard 0.581 (Validation)\n",
      "Epoch: [8] TotalTime: 5.0 mins,  BatchTime: 0.321,  DataTime: 0.014,  Loss: 0.5683,  Jaccard: 0.6155\n",
      " * Loss 0.716 Jaccard 0.603 (Validation)\n",
      "Epoch: [9] TotalTime: 5.6 mins,  BatchTime: 0.322,  DataTime: 0.015,  Loss: 0.5711,  Jaccard: 0.6090\n",
      " * Loss 0.713 Jaccard 0.594 (Validation)\n",
      "Epoch: [10] TotalTime: 6.2 mins,  BatchTime: 0.324,  DataTime: 0.016,  Loss: 0.5561,  Jaccard: 0.6486\n",
      " * Loss 0.728 Jaccard 0.543 (Validation)\n",
      "Epoch: [11] TotalTime: 6.7 mins,  BatchTime: 0.326,  DataTime: 0.017,  Loss: 0.5570,  Jaccard: 0.6468\n",
      " * Loss 0.733 Jaccard 0.552 (Validation)\n",
      "Epoch    11: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch: [12] TotalTime: 7.3 mins,  BatchTime: 0.322,  DataTime: 0.015,  Loss: 0.5525,  Jaccard: 0.6570\n",
      " * Loss 0.712 Jaccard 0.608 (Validation)\n",
      "Epoch: [13] TotalTime: 7.8 mins,  BatchTime: 0.323,  DataTime: 0.016,  Loss: 0.5522,  Jaccard: 0.6588\n",
      " * Loss 0.709 Jaccard 0.617 (Validation)\n",
      "Epoch: [14] TotalTime: 8.4 mins,  BatchTime: 0.324,  DataTime: 0.017,  Loss: 0.5466,  Jaccard: 0.6734\n",
      " * Loss 0.708 Jaccard 0.618 (Validation)\n",
      "Epoch: [15] TotalTime: 9.0 mins,  BatchTime: 0.322,  DataTime: 0.015,  Loss: 0.5447,  Jaccard: 0.6794\n",
      " * Loss 0.707 Jaccard 0.613 (Validation)\n",
      "Epoch: [16] TotalTime: 9.5 mins,  BatchTime: 0.331,  DataTime: 0.023,  Loss: 0.5427,  Jaccard: 0.6847\n",
      " * Loss 0.721 Jaccard 0.578 (Validation)\n",
      "Epoch: [17] TotalTime: 10.1 mins,  BatchTime: 0.322,  DataTime: 0.014,  Loss: 0.5446,  Jaccard: 0.6805\n",
      " * Loss 0.709 Jaccard 0.620 (Validation)\n",
      "Epoch: [18] TotalTime: 10.6 mins,  BatchTime: 0.322,  DataTime: 0.014,  Loss: 0.5415,  Jaccard: 0.6893\n",
      " * Loss 0.708 Jaccard 0.619 (Validation)\n",
      "Epoch: [19] TotalTime: 11.2 mins,  BatchTime: 0.323,  DataTime: 0.016,  Loss: 0.5409,  Jaccard: 0.6902\n",
      " * Loss 0.715 Jaccard 0.603 (Validation)\n",
      "Epoch: [20] TotalTime: 11.8 mins,  BatchTime: 0.324,  DataTime: 0.016,  Loss: 0.5394,  Jaccard: 0.6958\n",
      " * Loss 0.708 Jaccard 0.624 (Validation)\n",
      "Epoch: [21] TotalTime: 12.3 mins,  BatchTime: 0.322,  DataTime: 0.015,  Loss: 0.5432,  Jaccard: 0.6837\n",
      " * Loss 0.707 Jaccard 0.625 (Validation)\n",
      "Epoch: [22] TotalTime: 12.9 mins,  BatchTime: 0.323,  DataTime: 0.015,  Loss: 0.5403,  Jaccard: 0.6923\n",
      " * Loss 0.709 Jaccard 0.620 (Validation)\n",
      "Epoch: [23] TotalTime: 13.4 mins,  BatchTime: 0.324,  DataTime: 0.016,  Loss: 0.5418,  Jaccard: 0.6884\n",
      " * Loss 0.706 Jaccard 0.626 (Validation)\n",
      "Epoch: [24] TotalTime: 14.0 mins,  BatchTime: 0.322,  DataTime: 0.015,  Loss: 0.5362,  Jaccard: 0.7040\n",
      " * Loss 0.707 Jaccard 0.632 (Validation)\n",
      "Epoch: [25] TotalTime: 14.6 mins,  BatchTime: 0.324,  DataTime: 0.016,  Loss: 0.5418,  Jaccard: 0.6872\n",
      " * Loss 0.705 Jaccard 0.630 (Validation)\n",
      "Epoch: [26] TotalTime: 15.1 mins,  BatchTime: 0.332,  DataTime: 0.024,  Loss: 0.5374,  Jaccard: 0.7003\n",
      " * Loss 0.705 Jaccard 0.635 (Validation)\n",
      "Epoch: [27] TotalTime: 15.7 mins,  BatchTime: 0.322,  DataTime: 0.014,  Loss: 0.5379,  Jaccard: 0.6991\n",
      " * Loss 0.710 Jaccard 0.618 (Validation)\n",
      "Epoch: [28] TotalTime: 16.3 mins,  BatchTime: 0.324,  DataTime: 0.016,  Loss: 0.5374,  Jaccard: 0.7002\n",
      " * Loss 0.706 Jaccard 0.634 (Validation)\n",
      "Epoch: [29] TotalTime: 16.8 mins,  BatchTime: 0.323,  DataTime: 0.015,  Loss: 0.5390,  Jaccard: 0.6958\n",
      " * Loss 0.708 Jaccard 0.627 (Validation)\n",
      "Epoch    29: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch: [30] TotalTime: 17.4 mins,  BatchTime: 0.330,  DataTime: 0.022,  Loss: 0.5350,  Jaccard: 0.7073\n",
      " * Loss 0.707 Jaccard 0.630 (Validation)\n",
      "Epoch: [31] TotalTime: 17.9 mins,  BatchTime: 0.330,  DataTime: 0.021,  Loss: 0.5337,  Jaccard: 0.7115\n",
      " * Loss 0.708 Jaccard 0.625 (Validation)\n",
      "Epoch: [32] TotalTime: 18.5 mins,  BatchTime: 0.329,  DataTime: 0.021,  Loss: 0.5316,  Jaccard: 0.7172\n",
      " * Loss 0.709 Jaccard 0.620 (Validation)\n",
      "Epoch    32: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch: [33] TotalTime: 19.1 mins,  BatchTime: 0.323,  DataTime: 0.016,  Loss: 0.5356,  Jaccard: 0.7054\n",
      " * Loss 0.708 Jaccard 0.626 (Validation)\n",
      "Epoch: [34] TotalTime: 19.6 mins,  BatchTime: 0.324,  DataTime: 0.016,  Loss: 0.5321,  Jaccard: 0.7158\n",
      " * Loss 0.706 Jaccard 0.634 (Validation)\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "class_list = [\"Buildings\", \"Misc. Manmade structures\", \"Road\", \"Track\", \"Trees\", \"Crops\", \"Waterway\",\n",
    "              \"Standing Water\", \"Vehicle Large\", \"Vehicle Small\"]\n",
    "# classes = list(range(10))\n",
    "classes = [0]\n",
    "classes_string = \"_\".join([class_list[j] for j in classes])\n",
    "hps = HyperParams()\n",
    "hps.update(\"net=UNet_BN,bn=1,classes={}\".format(\"-\".join([str(j) for j in classes])))\n",
    "\n",
    "pprint(attr.asdict(hps))\n",
    "main(\"UNet_BN_classes_{}_crop80_lr0.1_noaugm_logloss0.1_dice_0.9_bs256_sample20k\".format(\"_\".join([str(j) for j in classes])), hps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dstl]",
   "language": "python",
   "name": "conda-env-dstl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "4px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
